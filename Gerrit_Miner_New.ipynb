{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import requests_futures.sessions\n",
    "import concurrent.futures\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "#the url for the gerrit repo we want to mine.\n",
    "#For a new repo, we need to know the url of the new repo\n",
    "libreoffice_url = 'https://gerrit.libreoffice.org/changes/'\n",
    "example_url = 'https://gerrit.XX.com/a/changes/'\n",
    "\n",
    "#adjust this variable to point to the url that the rest of the code will use\n",
    "current_project_name = libreoffice_url\n",
    "\n",
    "#set the dates to choose the earliest date to mine the repo.\n",
    "#by default the end date is the current date\n",
    "start_year = 2011\n",
    "start_month = 11\n",
    "start_day = 14\n",
    "\n",
    "#to be filled with relevant info. It is case sensitive\n",
    "username = \"umarIftikhar\"\n",
    "httpassword = \"0pZR3tEp61m195KHpl+YRV7f/IOeWgqNj4N3HoZqBg\"\n",
    "\n",
    "\n",
    "#HTTP adapter initiation\n",
    "retries = requests.packages.urllib3.util.retry.Retry(\n",
    "    total=10, \n",
    "    backoff_factor=2, \n",
    "    status_forcelist=[401, 429, 500, 502, 503, 504]\n",
    ")\n",
    "http_adapter = requests.adapters.HTTPAdapter(max_retries=retries)\n",
    "timeout = 10*60\n",
    "\n",
    "#data slics function\n",
    "def date_slices(from_date, to_date):\n",
    "    for ordinal in range(from_date.toordinal(), to_date.toordinal()):\n",
    "        start = datetime.datetime.fromordinal(ordinal)\n",
    "        end = start + datetime.timedelta(days=1, milliseconds=-1)\n",
    "        yield (str(start), str(end)[:-3])\n",
    "\n",
    "#Note: update the earliest date you are interested in mining/or available in your repo\n",
    "first_change = datetime.datetime(year=start_year, month=start_month, day=start_day)\n",
    "days = list(date_slices(first_change, datetime.datetime.today()))\n",
    "\n",
    "#helper function to print dataframe as json needed during debugging\n",
    "def print_file_data(filename):\n",
    "    # Open the JSON file for reading\n",
    "    with open(filename, 'r') as file:\n",
    "        # Load the JSON data\n",
    "        data = json.load(file)\n",
    "    # Print the JSON data with proper indentation\n",
    "    print(json.dumps(data, indent=4))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18596648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------extracting all changes from current_project_name between dates stated above\n",
    "with requests_futures.sessions.FuturesSession(max_workers=4) as session:\n",
    "    session.mount(\"https://\", http_adapter)\n",
    "    # Set up basic authentication\n",
    "    #authentication code\n",
    "    session.auth = HTTPBasicAuth(username, httpassword)\n",
    "    params = [()]\n",
    "  \n",
    "    changes_futures = [session.get(current_project_name,params={'q': 'after:\"{}\" AND until:\"{}\"'.format(start, end)}) for (start, end) in days]\n",
    "    \n",
    "    for future in tqdm(concurrent.futures.as_completed(changes_futures), total=len(changes_futures)): \n",
    "        future.done()\n",
    "\n",
    "changes = []\n",
    "for f in changes_futures:\n",
    "    r = json.loads(f.result().text[len(\"]}\\\\\\'\\n\"):])\n",
    "    assert isinstance(r, list), 'Parsed response is not a list'\n",
    "    changes += r\n",
    "\n",
    "#-------saving the changes after filtered by project ------------ \n",
    "changes_list = pd.DataFrame(changes)\n",
    "changes_list.to_csv(\"new_changes.csv\")\n",
    "print(\"all new changes written to file\")   \n",
    "\n",
    "#Uncomment if you want to print the changes\n",
    "#for change in changes:\n",
    "#    print(change[\"_number\"],change[\"total_comment_count\"],change[\"created\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8611204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------comments info extraction\n",
    "with requests_futures.sessions.FuturesSession(max_workers=8) as session:\n",
    "     session.mount(\"https://\", http_adapter)\n",
    "\n",
    "     # authentication code\n",
    "     session.auth = HTTPBasicAuth(username, httpassword)\n",
    "\n",
    "     comments_futures = [session.get(current_project_name+'{}/comments'.format(change['_number'])) for change in changes]\n",
    "    \n",
    "     for future in tqdm(concurrent.futures.as_completed(comments_futures), total=len(comments_futures)):\n",
    "         future.done()\n",
    "\n",
    "comments = {}\n",
    "for f in comments_futures:\n",
    "    try:\n",
    "        r = json.loads(f.result().text[len(\"]}\\\\\\'\\n\"):])\n",
    "    except:\n",
    "        print(f.result().text)\n",
    "    comments[f.result().url.split('/')[4]] = r\n",
    "  \n",
    "with open('rawLibreOfficeData.json', 'w') as json_file:\n",
    "    json.dump(comments, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#This is the same file we saved in the last section\n",
    "filename = 'rawLibreOfficeData.json'\n",
    "\n",
    "# Opening JSON file\n",
    "f = open(filename)\n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "single_comment_list = []\n",
    "comments_for_proj = []\n",
    "\n",
    "for rec,value in data.items():\n",
    "    for key,comment_values in value.items():\n",
    "        for list_comment_data in comment_values: \n",
    "            comment = str(list_comment_data['message'])\n",
    "            #remove tabs and carriage returns from the comments\n",
    "            comment = comment.replace('\\n','')\n",
    "            comment = comment.replace('\\r','')\n",
    "            comment = comment.replace('\\t','')\n",
    "            single_comment_list = [rec, key, list_comment_data['author']['name'],list_comment_data['unresolved'],list_comment_data['patch_set'],list_comment_data['updated'],comment,list_comment_data['commit_id'], list_comment_data['author']['_account_id']]\n",
    "            #print(single_comment_list)\n",
    "            comments_for_proj.append(single_comment_list)\n",
    "\n",
    "tobe_saved_comments = pd.DataFrame(comments_for_proj, columns=('ChangeID', 'FileName', 'AuthorName', 'Unresolved','PatchSet','UpdateDate','comment','CommitID','AuthorID'))\n",
    "#The csv will be the input to the data preprocessing code in 'PreprocessingTM_Gerrit.ipynb'\n",
    "tobe_saved_comments.to_csv(\"review_comments.csv\")\n",
    "\n",
    "#remove illegal characters before saving the file as xlsx\n",
    "tobe_saved_comments = tobe_saved_comments.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "tobe_saved_comments.to_excel(\"review_comments00.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ed888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e61527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "# import datetime\n",
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "\n",
    "# #helper function to print dataframe as json needed during debugging\n",
    "# def print_file_data(filename):\n",
    "#     # Open the JSON file for reading\n",
    "#     with open(filename, 'r') as file:\n",
    "#         # Load the JSON data\n",
    "#         data = json.load(file)\n",
    "#     # Print the JSON data with proper indentation\n",
    "#     print(json.dumps(data, indent=4))\n",
    "\n",
    "# print_file_data(\"rawLibreOfficeData.json\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
