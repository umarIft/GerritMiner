{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c564e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This file implements coherence calculation for topics generated by STTM. \n",
    "#It needs excel file where the cleaned comments are stored to create the dictinary\n",
    "#It also needs the text file name and full path from where it reads generated topics.\n",
    "#Then it uses coherence model to generate coherence for topics and the dictionary given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9dfa70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Cleaned_comment\n",
      "1    decision record case unclear review imho indic...\n",
      "2    necessary inject preferencesservice line think...\n",
      "3    think purpose replace static call instance cal...\n",
      "4    propose class static singleton public construc...\n",
      "5    understood correctly method extracted filelist...\n",
      "..                                                 ...\n",
      "530                                         jsonobject\n",
      "531                    query parser instead regex good\n",
      "532                                         reame task\n",
      "533                                         downloaded\n",
      "534                                  currenttotalwidth\n",
      "\n",
      "[534 rows x 1 columns]\n",
      "Dictionary<1658 unique tokens: ['adrs', 'based', 'browser', 'case', 'code']...>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "#load the excel file to read cleaned_comments and generate the needed dictionary\n",
    "\n",
    "#Note: change the filepath of the OSS corpus and the sheet_name as well the number of rows to consider\n",
    "\n",
    "#num_rows = 4884 #4884\n",
    "#curr_sheet = \"AllVerM\" #\"AllVerM\"\n",
    "num_rows = 535\n",
    "curr_sheet = \"AllVerAB\"\n",
    "\n",
    "filename = \"~/dev/topic_modeling/Jabref_pullrequest_comments_bert.xlsx\"\n",
    "jb_data=pd.read_excel(filename,sheet_name=curr_sheet,nrows=num_rows)\n",
    "oss_corpus = pd.DataFrame(jb_data,columns=['Cleaned_comment'])\n",
    "\n",
    "mono_corpus = oss_corpus[1:num_rows]\n",
    "oss_corpus1 = mono_corpus\n",
    "print(oss_corpus1)\n",
    "ret = oss_corpus1['Cleaned_comment']\n",
    "text_tokens = [[text for text in str(ret).split()] for ret in ret]\n",
    "dict_LoS = Dictionary(text_tokens)\n",
    "print(dict_LoS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f569397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Load the top terms from the all the topics in the file. Store it as a list of lists.\n",
    "\n",
    "def load_data(file_path):\n",
    "    \n",
    "    # Initialize an empty list to store the lines\n",
    "    lines = []    \n",
    "    # Open the file and read its contents\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read each line in the file\n",
    "        for line in file:\n",
    "            # Strip any leading or trailing whitespace\n",
    "            line = line.strip()\n",
    "            # Split the line into individual words\n",
    "            words = line.split()\n",
    "            # Add the list of words to the lines list\n",
    "            lines.append(words)\n",
    "    return lines\n",
    "\n",
    "def writelist_to_file(data, file_path):\n",
    "    with open(file_path, 'a') as file:\n",
    "        for row in data:\n",
    "            # Writing the row to the file\n",
    "            file.write(str(row)+'\\n')\n",
    "\n",
    "def coherence_calculation_for_file(data,text_tokens,dict_LoS):\n",
    "    lines_count=0\n",
    "    topics=[]\n",
    "    coherence_scores = []\n",
    "    for i in range(0,len(data)): \n",
    "        if(not data[i]):\n",
    "            if(len(topics)>0):\n",
    "                #print(topics)\n",
    "                # Coherence model\n",
    "                \n",
    "                cm = CoherenceModel(topics=topics, texts=text_tokens,coherence='c_v',dictionary=dict_LoS)\n",
    "                coherence_model = cm.get_coherence()\n",
    "                #print(lines_count)\n",
    "                coherence_scores.append(str(lines_count)+\" \"+str(coherence_model))\n",
    "            topics=[]\n",
    "            lines_count=0\n",
    "        else:\n",
    "            topics.append(data[i])\n",
    "            #count the number of topics in each run and store it as well\n",
    "            lines_count=  lines_count+1   \n",
    "    return coherence_scores              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0331a63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = load_data(\"resultsSS_05.txt\")\n",
    "coherence_scores = coherence_calculation_for_file(data,text_tokens,dict_LoS) \n",
    "writelist_to_file(coherence_scores,\"BT_Kmeans_coherence_scoreAB_S05.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3192650",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = load_data(\"resultsSS_10.txt\")\n",
    "coherence_scores = coherence_calculation_for_file(data,text_tokens,dict_LoS) \n",
    "writelist_to_file(coherence_scores,\"BT_Kmeans_coherence_scoreAB_S10.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95e1d241",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = load_data(\"resultsSS_15.txt\")\n",
    "coherence_scores = coherence_calculation_for_file(data,text_tokens,dict_LoS) \n",
    "writelist_to_file(coherence_scores,\"BT_Kmeans_coherence_scoreAB_S15.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "611e5405",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = load_data(\"resultsSS_20.txt\")\n",
    "coherence_scores = coherence_calculation_for_file(data,text_tokens,dict_LoS) \n",
    "writelist_to_file(coherence_scores,\"BT_Kmeans_coherence_scoreAB_S20.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7defccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"resultsSS_25.txt\")\n",
    "coherence_scores = coherence_calculation_for_file(data,text_tokens,dict_LoS) \n",
    "writelist_to_file(coherence_scores,\"BT_Kmeans_coherence_scoreAB_S25.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06c222fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"resultsSS_30.txt\")\n",
    "coherence_scores = coherence_calculation_for_file(data,text_tokens,dict_LoS) \n",
    "writelist_to_file(coherence_scores,\"BT_Kmeans_coherence_scoreAB_S30.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff644907",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"resultsSS_35.txt\")\n",
    "coherence_scores = coherence_calculation_for_file(data,text_tokens,dict_LoS) \n",
    "writelist_to_file(coherence_scores,\"BT_Kmeans_coherence_scoreAB_S35.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b230f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"resultsSS_40.txt\")\n",
    "coherence_scores = coherence_calculation_for_file(data,text_tokens,dict_LoS) \n",
    "writelist_to_file(coherence_scores,\"BT_Kmeans_coherence_scoreAB_S40.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d6e2b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"resultsSS_45.txt\")\n",
    "coherence_scores = coherence_calculation_for_file(data,text_tokens,dict_LoS) \n",
    "writelist_to_file(coherence_scores,\"BT_Kmeans_coherence_scoreAB_S45.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cc3479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"resultsSS_50.txt\")\n",
    "coherence_scores = coherence_calculation_for_file(data,text_tokens,dict_LoS) \n",
    "writelist_to_file(coherence_scores,\"BT_Kmeans_coherence_scoreAB_S50.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46561868",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"resultsSS_55.txt\")\n",
    "coherence_scores = coherence_calculation_for_file(data,text_tokens,dict_LoS) \n",
    "writelist_to_file(coherence_scores,\"BT_Kmeans_coherence_scoreAB_S55.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd005fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c95b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490367c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9795a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f5584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3fbe52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52916740",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for diversity in range(1,10,1): #divide by ten\n",
    "    for ngram_max in range (1,10):\n",
    "        for ngram_min in range (1,ngram_max):\n",
    "            list.append(str(ngram_min)+\" \"+str(ngram_max)+\" \"+str(diversity/10))      \n",
    "\n",
    "writelist_to_file(list,\"Bertopic_params.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
